## 1. 项目概述

本项目旨在实现一个基于视觉的机器人自动化抓取系统。核心任务是控制一台 **Tinkerbot Braccio 五轴机械臂**，利用 **Logitech C270 摄像头** 识别并抓取一个乐高（Lego）积木块。

## 2. 系统组成

### 2.1 硬件平台

- **执行机构**: Tinkerbot Braccio 五轴机械臂
    
- **视觉传感器**: Logitech C270 摄像头
    

### 2.2 软件与控制

- **编程语言**: Python
    
- **目标检测**: YOLO (You Only Look Once) 算法
    
- **机械臂控制**:
    
    - **通信方式**: 通过PC串口连接机械臂控制主板。
        
    - **控制指令**: 发送一个包含7个参数的数组，具体定义如下：
        
        1. 关节1角度
            
        2. 关节2角度
            
        3. 关节3角度
            
        4. 关节4角度
            
        5. 关节5角度
            
        6. 手爪（Grip）开合度
            
        7. 整体移动速度
            
    - **运动学代码**: 已具备成熟的前向运动学（Forward Kinematics, FK）和逆向运动学（Inverse Kinematics, IK）的Python函数库。
        

## 3. 核心技术路径与坐标系定义

为了将摄像头捕捉到的视觉信息转化为机械臂可以执行的动作，我们需要打通从像素到物理空间的坐标转换。为此，我们定义以下三个关键坐标系：

- **坐标系 A (图像坐标系 - Image Coordinate System)**
    
    - **原点**: 图像左上角
        
    - **单位**: 像素 (pixel)
        
    - **描述**: YOLO算法检测出的目标（乐高积木）位置位于此坐标系中。
        
- **坐标系 B (世界坐标系 - World Coordinate System)**
    
    - **原点**: 实验台平面上的某个物理参考点
        
    - **单位**: 物理单位（如：毫米 mm）
        
    - **描述**: 摄像头视野内，积木所在的真实二维平面。这是连接视觉和机器人世界的“桥梁”。
        
- **坐标系 C (机械臂基座坐标系 - Robot Base Coordinate System)**
    
    - **原点**: 机械臂底座（Base）的中心点
        
    - **单位**: 物理单位（如：毫米 mm）
        
    - **描述**: 机械臂逆向运动学（IK）函数所接受的输入坐标参考系。所有目标抓取点必须转换到此坐标系下，IK函数才能求解出正确的关节角度。
        

### 预期工作流程

整个系统的理想数据流应如下所示：

```
graph TD
    A[YOLO检测结果: 积木像素坐标 (坐标系A)] -->|步骤1: 相机标定与平面校准| B(积木在平面上的物理坐标 (坐标系B));
    B -->|步骤2: 手眼标定| C(积木在机械臂下的物理坐标 (坐标系C));
    C -->|输入IK函数| D(逆向运动学函数求解);
    D --> E{计算出的5个关节参数};
    E --> F[组合成7参数控制指令];
    F --> G[通过串口发送给机械臂];
    G --> H[机械臂执行抓取动作];
```

## 4. 当前项目进展

当前阶段，以下模块已经完成：

1. **机械臂底层控制**: 已拥有完整的前向控制Python代码，可以向机械臂发送7参数数组并驱动其运动。这通过 `ForwardController.py` 实现。
    
2. **逆向运动学求解**: 已拥有可靠的逆向计算（IK）函数。该函数能够：
    
    - 根据一个在**坐标系C**下的三维空间坐标，计算出对应的5个关节参数。这通过 `InverseCalculate.py` 实现。
        
    - 判断该目标坐标点对机械臂是否可达。
        
3. **目标视觉识别**: 已成功部署YOLO算法，能够驱动C270摄像头，并实时、准确地识别出画面中的乐高积木块，输出其在**坐标系A**中的像素位置。
    

## 5. 核心挑战与待解决问题

尽管主要模块功能正常，但项目在"系统集成"层面遇到了关键瓶颈，即**坐标系的转换与对齐**问题。具体来说，我们当前缺失以下两个核心环节的有效方法：

1. **相机内参标定与平面校准 (A → B 的映射)**
    
    - **问题描述**: 由于摄像头每次安装的位置和角度都可能发生变化，导致像素坐标（坐标系A）与真实世界平面坐标（坐标系B）之间的映射关系（如透视变换、畸变等）是不固定的。我们需要一个有效的校准流程来确定这个映射关系。
        
2. **手眼标定 (B → C 的映射)**
    
    - **问题描述**: 仅仅得到积木在世界平面（坐标系B）上的坐标是不够的，机械臂需要知道这个“世界平面”相对于它自身基座（坐标系C）的位置和姿态。我们需要一个手眼标定流程来建立这两个物理坐标系之间的转换矩阵。

3. **关于z轴高度参数的考虑**
    - **问题描述**：由于摄像头无法拍摄到深度或者高度信息，只能获取一个二维平面的坐标信息，也就是说坐标轴A以及坐标轴B都是二维坐标系。然后坐标轴C是一个三维坐标系。但是我们可以通过限定Z轴高度参数的方法来解决这个问题。由于我们已经测量过了目标Lego积木方块的高度是固定的2厘米，因此仅需指定机械臂griper到高度为2厘米的地方抓取即可，也就是说这个Z轴参数是固定的。那么现在就可以通过手眼标定来实现B到C坐标系的对齐了。